# Local AI Stack Setup Guide for Kwintes
# Created and maintained by Z4Y
# Includes: n8n, Ollama, Qdrant, Prometheus, Grafana, Whisper, and Python

## Prerequisites
1. Server Requirements
   - Ubuntu 22.04 LTS or newer
   - Minimum 16GB RAM
   - 100GB+ storage
   - Domain name with DNS access

2. Server Access Information
   - IP: 46.202.155.155
   - Username: root
   - Password: [Your server password]

3. Domain Information
   - Current domain: kwintes.cloud
   - Required subdomains:
     * n8n.kwintes.cloud
     * openwebui.kwintes.cloud
     * flowise.kwintes.cloud
     * supabase.kwintes.cloud
     * grafana.kwintes.cloud
     * prometheus.kwintes.cloud
     * whisper.kwintes.cloud
     * qdrant.kwintes.cloud

## Server Setup Steps

### 1. Initial Server Setup
```bash
# Update system and install required packages
sudo apt update && sudo apt upgrade -y
sudo apt install -y nano git docker.io python3 python3-pip docker-compose ffmpeg portaudio19-dev python3-pyaudio

# Install Docker Compose v2
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Add current user to docker group
sudo usermod -aG docker $USER
```

### 2. Configure Firewall
```bash
# Enable and configure firewall
sudo ufw enable
sudo ufw allow 8000  # n8n
sudo ufw allow 3001  # Flowise
sudo ufw allow 3000  # Web UI
sudo ufw allow 5678  # n8n webhook
sudo ufw allow 80    # HTTP
sudo ufw allow 443   # HTTPS
sudo ufw allow 8080  # SearXNG (if needed)
sudo ufw allow 11434 # Ollama
sudo ufw allow 6333  # Qdrant
sudo ufw allow 9090  # Prometheus
sudo ufw allow 3000  # Grafana
sudo ufw reload
```

### 3. Clone Repository
```bash
# Clone the repository
git clone https://github.com/ThijsdeZeeuw/AVGKWINTES.git
cd AVGKWINTES

# Create necessary directories
mkdir -p data/{qdrant,prometheus,grafana,supabase}
```

### 4. Interactive Environment Setup
```bash
# Run the interactive setup script
python3 start_services.py --interactive

# The script will:
# - Generate secure random values for all secrets
# - Create a .env file with your configuration
# - Save all secrets to secrets.txt
# - Set up monitoring with Prometheus and Grafana
# - Initialize all services
```

### 5. Start Services
```bash
# Start all services
docker compose -p localai up -d

# Verify services are running
docker compose -p localai ps

# Check service logs if needed
docker compose -p localai logs -f [service_name]
```

### 6. Verify Installation
```bash
# Check running containers
docker ps

# Verify services are accessible
curl https://n8n.kwintes.cloud/healthz  # n8n
curl https://qdrant.kwintes.cloud/healthz  # Qdrant
curl https://prometheus.kwintes.cloud/-/healthy  # Prometheus
```

## Accessing Services

After installation, you can access the following services:

1. n8n: https://n8n.kwintes.cloud
2. Web UI: https://openwebui.kwintes.cloud
3. Flowise: https://flowise.kwintes.cloud
4. Supabase: https://supabase.kwintes.cloud
5. Grafana: https://grafana.kwintes.cloud
6. Prometheus: https://prometheus.kwintes.cloud
7. Whisper API: https://whisper.kwintes.cloud
8. Qdrant API: https://qdrant.kwintes.cloud

## Monitoring Setup

1. Access Grafana at https://grafana.kwintes.cloud
   - Default credentials: admin / (password from secrets.txt)
   - Add Prometheus as a data source (URL: http://prometheus:9090)

2. Access Prometheus at https://prometheus.kwintes.cloud
   - View metrics and create alerts

## Available AI Models

The following models are automatically installed:

### Large Language Models (LLMs)
- gemma3:12b (Google)
- granite3-guardian:8b (IBM)
- granite3.1-dense:latest (IBM)
- granite3.1-moe:3b (IBM)
- granite3.2:latest (IBM)
- llama3.2-vision (Meta)
- minicpm-v:8b (OpenBMB)
- mistral-nemo:12b (Mistral AI)
- qwen2.5:7b-instruct-q4_K_M (Alibaba)
- reader-lm:latest (OpenBMB)

### Embedding Models
- granite-embedding:278m (IBM)
- jeffh/intfloat-multilingual-e5-large-instruct:f16 (Hugging Face)
- nomic-embed-text:latest (Nomic AI)

## Maintenance

### Updating the Stack
```bash
cd AVGKWINTES
git pull
python3 start_services.py --interactive
```

### Restarting Services
```bash
docker compose -p localai down
python3 start_services.py --interactive
```

### Backup
```bash
# Backup data directories
tar -czf backup_$(date +%Y%m%d).tar.gz data/
```

## Security Notes

1. All secrets are saved to secrets.txt - keep this file secure
2. All services are configured to use HTTPS through Caddy
3. Firewall rules are configured to allow only necessary ports
4. Default credentials should be changed after first login
5. Regular security updates are handled through Docker containers

## Support

For issues and feature requests, please open an issue on the GitHub repository:
https://github.com/ThijsdeZeeuw/AVGKWINTES/issues

---
Created and maintained by Z4Y 