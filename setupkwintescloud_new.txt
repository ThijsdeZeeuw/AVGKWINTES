# Local AI Stack Setup Guide for Kwintes
# Created and maintained by Z4Y

## Prerequisites

### Server Requirements
- Ubuntu 22.04 LTS or newer
- Minimum 16GB RAM
- 100GB+ storage
- Domain name with DNS access

### Server Access Information
- IP Address: [Your Server IP]
- Username: [Your Username]
- Password: [Your Password]

### Required Subdomains
- n8n.kwintes.cloud
- openwebui.kwintes.cloud
- flowise.kwintes.cloud
- supabase.kwintes.cloud
- ollama.kwintes.cloud
- searxng.kwintes.cloud
- grafana.kwintes.cloud
- prometheus.kwintes.cloud
- whisper.kwintes.cloud
- qdrant.kwintes.cloud

## Server Setup Steps

### 1. System Update and Package Installation
```bash
# Update system packages
sudo apt update && sudo apt upgrade -y

# Install required packages
sudo apt install -y \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg \
    lsb-release \
    python3 \
    python3-pip \
    python3-venv \
    git \
    build-essential \
    software-properties-common \
    nginx \
    certbot \
    python3-certbot-nginx

# Install Python dependencies
pip3 install --upgrade pip
pip3 install pydantic pydantic-settings python-dotenv docker
```

### 2. Docker Installation
```bash
# Remove old Docker installations
sudo apt remove -y docker docker-engine docker.io containerd runc

# Install Docker prerequisites
sudo apt update
sudo apt install -y \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg \
    lsb-release

# Add Docker's official GPG key
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# Add Docker repository
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Install Docker Engine
sudo apt update
sudo apt install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin

# Add user to docker group
sudo usermod -aG docker $USER
```

### 3. Firewall Configuration
```bash
# Configure UFW
sudo ufw allow OpenSSH
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw allow 8000/tcp
sudo ufw allow 3000/tcp
sudo ufw allow 3001/tcp
sudo ufw allow 11434/tcp
sudo ufw allow 8080/tcp
sudo ufw allow 9090/tcp
sudo ufw allow 9000/tcp
sudo ufw allow 6333/tcp
sudo ufw enable
```

### 4. Repository Setup
```bash
# Clone repository
git clone https://github.com/ThijsdeZeeuw/AVGKWINTES.git
cd AVGKWINTES

# Create data directories
mkdir -p data/{n8n,flowise,webui,supabase,ollama,searxng,prometheus,grafana,whisper,qdrant}
chmod -R 755 data
```

### 5. Environment Setup
```bash
# Create and activate virtual environment
python3 -m venv venv
source venv/bin/activate

# Install Python dependencies
pip install -r requirements.txt

# Run interactive setup script
python start_services.py --interactive
```

### 6. Service Installation and Configuration

#### 6.1 n8n Setup
```bash
# n8n will be automatically configured through docker-compose
# Access at https://n8n.kwintes.cloud
```

#### 6.2 Flowise Setup
```bash
# Flowise will be automatically configured through docker-compose
# Access at https://flowise.kwintes.cloud
```

#### 6.3 WebUI Setup
```bash
# WebUI will be automatically configured through docker-compose
# Access at https://openwebui.kwintes.cloud
```

#### 6.4 Supabase Setup
```bash
# Supabase will be automatically configured through docker-compose
# Access at https://supabase.kwintes.cloud
```

#### 6.5 Ollama Setup
```bash
# Ollama will be automatically configured through docker-compose
# Access at https://ollama.kwintes.cloud
```

#### 6.6 SearXNG Setup
```bash
# SearXNG will be automatically configured through docker-compose
# Access at https://searxng.kwintes.cloud
```

#### 6.7 Grafana Setup
```bash
# Grafana will be automatically configured through docker-compose
# Access at https://grafana.kwintes.cloud
```

#### 6.8 Prometheus Setup
```bash
# Prometheus will be automatically configured through docker-compose
# Access at https://prometheus.kwintes.cloud
```

#### 6.9 Whisper Setup
```bash
# Whisper will be automatically configured through docker-compose
# Access at https://whisper.kwintes.cloud
```

#### 6.10 Qdrant Setup
```bash
# Qdrant will be automatically configured through docker-compose
# Access at https://qdrant.kwintes.cloud
```

### 7. Starting Services
```bash
# Start all services
docker-compose up -d

# Check service status
docker-compose ps
```

### 8. Verifying Installation
```bash
# Check service logs
docker-compose logs -f

# Check service health
curl -I https://n8n.kwintes.cloud
curl -I https://flowise.kwintes.cloud
curl -I https://openwebui.kwintes.cloud
curl -I https://supabase.kwintes.cloud
curl -I https://ollama.kwintes.cloud
curl -I https://searxng.kwintes.cloud
curl -I https://grafana.kwintes.cloud
curl -I https://prometheus.kwintes.cloud
curl -I https://whisper.kwintes.cloud
curl -I https://qdrant.kwintes.cloud
```

## Available AI Models

### Large Language Models (LLMs)
1. gemma3:12b
   - Source: Google
   - Description: 12B parameter model with strong reasoning capabilities

2. granite3-guardian:8b
   - Source: IBM
   - Description: 8B parameter model with enhanced security features

3. llama2:13b
   - Source: Meta
   - Description: 13B parameter model with strong general capabilities

4. llama2:7b
   - Source: Meta
   - Description: 7B parameter model optimized for efficiency

5. mistral:7b
   - Source: Mistral AI
   - Description: 7B parameter model with excellent performance

6. mistral:7b-instruct
   - Source: Mistral AI
   - Description: Instruction-tuned version of Mistral 7B

7. mistral:7b-openorca
   - Source: Mistral AI
   - Description: OpenOrca fine-tuned version of Mistral 7B

8. mistral:7b-solar
   - Source: Mistral AI
   - Description: Solar fine-tuned version of Mistral 7B

9. mistral:7b-solar-instruct
   - Source: Mistral AI
   - Description: Instruction-tuned version of Mistral 7B Solar

10. mistral:7b-solar-openorca
    - Source: Mistral AI
    - Description: OpenOrca fine-tuned version of Mistral 7B Solar

11. mistral:7b-solar-openorca-instruct
    - Source: Mistral AI
    - Description: Instruction-tuned version of Mistral 7B Solar OpenOrca

12. mistral:7b-solar-openorca-instruct-v2
    - Source: Mistral AI
    - Description: V2 version of the instruction-tuned Mistral 7B Solar OpenOrca

13. mistral:7b-solar-openorca-instruct-v2.1
    - Source: Mistral AI
    - Description: V2.1 version of the instruction-tuned Mistral 7B Solar OpenOrca

### Embedding Models
1. granite-embedding:278m
   - Source: IBM
   - Description: 278M parameter model optimized for text embeddings

2. mistral-embedding:7b
   - Source: Mistral AI
   - Description: 7B parameter model for high-quality text embeddings

## Maintenance

### Regular Updates
```bash
# Update system packages
sudo apt update && sudo apt upgrade -y

# Update Docker images
docker-compose pull
docker-compose up -d

# Update Python dependencies
pip install --upgrade -r requirements.txt
```

### Backup Procedures
```bash
# Backup data directories
tar -czf backup_$(date +%Y%m%d).tar.gz data/

# Backup environment files
cp .env .env.backup
cp secrets.txt secrets.txt.backup
```

### Monitoring
```bash
# Check service logs
docker-compose logs -f

# Monitor system resources
htop
```

## Security Notes

1. All services are configured with HTTPS
2. Firewall rules are in place
3. Regular security updates are applied
4. Secrets are stored securely
5. Access is restricted to authorized users

## Support

For support or issues:
1. Check the logs: `docker-compose logs -f`
2. Verify service status: `docker-compose ps`
3. Check system resources: `htop`
4. Review security logs: `journalctl -u docker`

# Created and maintained by Z4Y 